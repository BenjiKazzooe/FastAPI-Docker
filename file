from fastapi import FastAPI
import kagglehub
import pandas as pd
import numpy as np
from pydantic import BaseModel
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

app = FastAPI()

def load_and_train_model():
    """L√§dt die Daten, trainiert das Modell und gibt das trainierte Modell und den Skalierer zur√ºck."""
    path = kagglehub.dataset_download("uciml/breast-cancer-wisconsin-data")
    data = pd.read_csv(f"{path}/data.csv")

    if 'Unnamed: 32' in data.columns:
        data = data.drop(columns=['Unnamed: 32'])

    X = data.drop(columns=['diagnosis'])
    y = data['diagnosis'].map({'B': 0, 'M': 1})

    print("\nüìä Verteilung der Klassen im Datensatz:")
    print(y.value_counts(normalize=True) * 100)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = MinMaxScaler()  # Alternative Skalierung, falls StandardScaler nicht optimal ist
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, random_state=42)
    model.fit(X_train_scaled, y_train)

    #Feature-Importanz ausgeben
    importances = model.feature_importances_
    feature_importance_df = pd.DataFrame({"Feature": X.columns, "Importance": importances})
    print("\nüî• Wichtigste Features f√ºr die Vorhersage:")
    print(feature_importance_df.sort_values(by="Importance", ascending=False).head(10))

    return model, scaler, X.columns.tolist()

model, scaler, feature_names = load_and_train_model()

class PredictionRequest(BaseModel):
    features: list[float]

@app.post("/predict")
def predict(request: PredictionRequest):
    """Nimmt eine Liste von Features und gibt die Krebsdiagnose-Vorhersage zur√ºck."""
    try:
        input_data = np.array(request.features).reshape(1, -1)

        # Anzahl der Features √ºberpr√ºfen
        print(f"\nüî¢ Erwartete Features: {len(feature_names)}, Erhalten: {len(input_data[0])}")
        if len(input_data[0]) != len(feature_names):
            return {"error": f"Falsche Anzahl an Features! Erwartet: {len(feature_names)}, Erhalten: {len(input_data[0])}"}

        input_scaled = scaler.transform(input_data)
        probability = model.predict_proba(input_scaled)[0][1]

        # Schwellenwert f√ºr "Malignant" 
        threshold = 0.6
        prediction = 1 if probability >= threshold else 0

        return {
            "prediction": "Malignant" if prediction == 1 else "Benign",
            "probability_malignant": round(probability, 2)
        }
    except Exception as e:
        return {"error": str(e)}

@app.get("/")
def root():
    return {"message": "Breast Cancer Prediction API l√§uft! Verwende POST /predict mit JSON-Daten f√ºr Vorhersagen."}
